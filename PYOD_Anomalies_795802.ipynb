{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQVVztLb6ikQZcBw/HFtt7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelCarbo/Anomalies-Detection-TFG/blob/main/PYOD_Anomalies_795802.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset Variables\n",
        "%reset"
      ],
      "metadata": {
        "id": "dLMEwTejzEg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b236b-c4e9-4a89-d0b9-bbc31fe22a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tz2rBsCy7M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325ac94e-28e7-4378-f55d-3c532df1f6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  pyod.zip\n",
            "replace pyod/models/abod.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: pyod/models/abod.py     \n",
            "  inflating: pyod/models/alad.py     \n",
            "  inflating: pyod/models/anogan.py   \n",
            "  inflating: pyod/models/auto_encoder.py  \n",
            "  inflating: pyod/models/auto_encoder_torch.py  \n",
            "  inflating: pyod/models/base.py     \n",
            "  inflating: pyod/models/base_dl.py  \n",
            "  inflating: pyod/models/cblof.py    \n",
            "  inflating: pyod/models/cd.py       \n",
            "  inflating: pyod/models/cof.py      \n",
            "  inflating: pyod/models/combination.py  \n",
            "  inflating: pyod/models/copod.py    \n",
            "  inflating: pyod/models/deep_svdd.py  \n",
            "  inflating: pyod/models/ecod.py     \n",
            "  inflating: pyod/models/feature_bagging.py  \n",
            "  inflating: pyod/models/gaal_base.py  \n",
            "  inflating: pyod/models/gmm.py      \n",
            "  inflating: pyod/models/hbos.py     \n",
            "  inflating: pyod/models/iforest.py  \n",
            "  inflating: pyod/models/inne.py     \n",
            "  inflating: pyod/models/kde.py      \n",
            "  inflating: pyod/models/knn.py      \n",
            "  inflating: pyod/models/kpca.py     \n",
            "  inflating: pyod/models/lmdd.py     \n",
            "  inflating: pyod/models/loci.py     \n",
            "  inflating: pyod/models/loda.py     \n",
            "  inflating: pyod/models/lof.py      \n",
            "  inflating: pyod/models/lscp.py     \n",
            "  inflating: pyod/models/lunar.py    \n",
            "  inflating: pyod/models/mad.py      \n",
            "  inflating: pyod/models/mcd.py      \n",
            "  inflating: pyod/models/mo_gaal.py  \n",
            "  inflating: pyod/models/ocsvm.py    \n",
            "  inflating: pyod/models/pca.py      \n",
            "  inflating: pyod/models/rgraph.py   \n",
            "  inflating: pyod/models/rod.py      \n",
            "  inflating: pyod/models/sampling.py  \n",
            "  inflating: pyod/models/sklearn_base.py  \n",
            "  inflating: pyod/models/sod.py      \n",
            "  inflating: pyod/models/sos.py      \n",
            "  inflating: pyod/models/so_gaal.py  \n",
            "  inflating: pyod/models/suod.py     \n",
            "  inflating: pyod/models/thresholds.py  \n",
            "  inflating: pyod/models/vae.py      \n",
            "  inflating: pyod/models/xgbod.py    \n",
            "  inflating: pyod/models/__init__.py  \n",
            "  inflating: pyod/utils/data.py      \n",
            "  inflating: pyod/utils/example.py   \n",
            "  inflating: pyod/utils/stat_models.py  \n",
            "  inflating: pyod/utils/torch_utility.py  \n",
            "  inflating: pyod/utils/utility.py   \n",
            "  inflating: pyod/utils/__init__.py  \n",
            "  inflating: pyod/version.py         \n",
            "  inflating: pyod/__init__.py        \n",
            "Archive:  zat.zip\n",
            "replace zat/dataframe_cache.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: zat/dataframe_cache.py  \n",
            "  inflating: zat/dataframe_stats.py  \n",
            "  inflating: zat/dataframe_to_matrix.py  \n",
            "  inflating: zat/data_generator.py   \n",
            "  inflating: zat/json_log_to_dataframe.py  \n",
            "  inflating: zat/live_simulator.py   \n",
            "  inflating: zat/log_to_dataframe.py  \n",
            "  inflating: zat/log_to_sparkdf.py   \n",
            "  inflating: zat/test_data/g_test_data.csv  \n",
            "  inflating: zat/utils/cache.py      \n",
            "  inflating: zat/utils/dir_watcher.py  \n",
            "  inflating: zat/utils/file_storage.py  \n",
            "  inflating: zat/utils/file_tailer.py  \n",
            "  inflating: zat/utils/file_utils.py  \n",
            "  inflating: zat/utils/geo_lookup.py  \n",
            "  inflating: zat/utils/net_utils.py  \n",
            "  inflating: zat/utils/ngrams.py     \n",
            "  inflating: zat/utils/plot_utils.py  \n",
            "  inflating: zat/utils/reverse_dns.py  \n",
            "  inflating: zat/utils/signal_utils.py  \n",
            "  inflating: zat/utils/vt_query.py   \n",
            "  inflating: zat/utils/__init__.py   \n",
            "  inflating: zat/zeek_log_reader.py  \n",
            "  inflating: zat/zeek_multi_log_reader.py  \n",
            "  inflating: zat/__init__.py         \n",
            "zat: 0.4.6\n",
            "Pandas: 1.3.5\n",
            "Numpy: 1.22.4\n",
            "Scikit Learn Version: 1.0.2\n"
          ]
        }
      ],
      "source": [
        "# C:\\Users\\mivar\\anaconda3\\pkgs\\pyod-1.0.7-pyhd8ed1ab_0\\site-packages\n",
        "# C:\\Users\\mivar\\Documents\\04_MIGUEL\\01UNIVERSIDAD\\TFG\\Zeek\\Packages\\zat-main\\zat-main\n",
        "\n",
        "# Packet Unzipping\n",
        "!unzip pyod.zip;\n",
        "!unzip zat.zip;\n",
        "\n",
        "# Import all models\n",
        "from pyod.models.abod import ABOD\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.lof import LOF\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.ecod import ECOD\n",
        "from pyod.models.copod import COPOD\n",
        "\n",
        "\n",
        "# Local Imports\n",
        "import zat;\n",
        "from zat.log_to_dataframe import LogToDataFrame;\n",
        "from zat.dataframe_to_matrix import DataFrameToMatrix;\n",
        "\n",
        "# Packet Imports\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "import sklearn;\n",
        "from sklearn.ensemble import IsolationForest;\n",
        "from sklearn.decomposition import PCA;\n",
        "from sklearn.cluster import KMeans, DBSCAN;\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from numpy import percentile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "\n",
        "# Version Printing\n",
        "print('zat: {:s}'.format(zat.__version__))\n",
        "print('Pandas: {:s}'.format(pd.__version__))\n",
        "print('Numpy: {:s}'.format(np.__version__))\n",
        "print('Scikit Learn Version:', sklearn.__version__)\n",
        "# print('PYOD Version: {:s}'.format(pyod.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. LOG TO CREATE DATAFRAME FROM ###"
      ],
      "metadata": {
        "id": "Jfa1jAg07hSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pandas dataframe from the Zeek log\n",
        "log_to_df = LogToDataFrame();\n",
        "conn_df = log_to_df.create_dataframe('mpli_conn_ts.log');\n",
        "print('Read in {:d} Rows...'.format(len(conn_df)))\n",
        "conn_df.columns"
      ],
      "metadata": {
        "id": "UOeFMp2jCFT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22908236-d78e-4176-db1f-7ad117bdefa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read in 323331 Rows...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sourceAddress', 'sourcePort', 'destinationAddress', 'destinationPort',\n",
              "       'service', 'duration', 'orig_bytes', 'resp_bytes', 'history',\n",
              "       'orig_pkts', 'resp_pkts', 'mediaOrigen', 'mediaResp', 'desvOrigen',\n",
              "       'desvResp', 'mediaTime', 'desvTime'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. FEATURE SELECTION ###"
      ],
      "metadata": {
        "id": "C6Pls2ff7mpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.A CONN.LOG FEATURES ####"
      ],
      "metadata": {
        "id": "aReOesA37pwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick some features that might be interesting\n",
        "features = ['proto','service','duration','orig_bytes','resp_bytes','conn_state',\n",
        "       'local_orig','local_resp','missed_bytes','history','orig_pkts',\n",
        "       'resp_pkts', 'tunnel_parents'];\n",
        "\n",
        "# features = ['service','duration','orig_bytes','resp_bytes','missed_bytes','history','tunnel_parents'];"
      ],
      "metadata": {
        "id": "q_s_o5KVCF2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B AMPLI_CONN.LOG FEATURES ####"
      ],
      "metadata": {
        "id": "AXMLxaoQrbYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lorena's Script Features\n",
        "\n",
        "# Complete Features\n",
        "full_features = ['ts','sourceAddress','sourcePort','destinationAddress','destinationPort','service','duration','orig_bytes','resp_bytes',\n",
        "           'history','orig_pkts','resp_pkts','mediaOrigen','mediaResp','desvOrigen','desvResp','mediaTime','desvTime' ]\n",
        "\n",
        "features = ['service','duration','orig_bytes','resp_bytes','history','orig_pkts','resp_pkts','mediaOrigen','mediaResp','desvOrigen','desvResp','mediaTime','desvTime' ]"
      ],
      "metadata": {
        "id": "1rHeRArxrjN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. DATA PREPARATION ###"
      ],
      "metadata": {
        "id": "IwgKNNwJ7voM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 DATA CLEANSING ####"
      ],
      "metadata": {
        "id": "c0WY6JNY71ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Filtering + NaNs removal\n",
        "conn_df = conn_df.dropna()\n",
        "conn_features_df = conn_df[features]"
      ],
      "metadata": {
        "id": "a7oaApZdrq0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing (Removing NaNs)\n",
        "for feature in features:\n",
        "    if (conn_features_df[feature].dtype.name == 'category') and ('0' not in conn_features_df[feature].cat.categories):\n",
        "        conn_features_df[feature] = conn_features_df[feature].cat.add_categories(['0'])\n",
        "        conn_features_df[feature] = conn_features_df[feature].fillna('0')\n",
        "    elif pd.api.types.is_timedelta64_dtype(conn_features_df[feature]): \n",
        "        conn_features_df[feature] = conn_features_df[feature].fillna(pd.Timedelta(0))\n",
        "        conn_features_df[feature] = conn_features_df[feature].dt.total_seconds().astype(int)\n",
        "\n",
        "    else: \n",
        "        conn_features_df[feature] = conn_features_df[feature].fillna(0)"
      ],
      "metadata": {
        "id": "6vXJ9rVp267o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7afc1f-0dbb-4fa9-fe84-cfc2e379e8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-b17b2be7c65d>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  conn_features_df[feature] = conn_features_df[feature].cat.add_categories(['0'])\n",
            "<ipython-input-132-b17b2be7c65d>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  conn_features_df[feature] = conn_features_df[feature].fillna('0')\n",
            "<ipython-input-132-b17b2be7c65d>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  conn_features_df[feature] = conn_features_df[feature].fillna(pd.Timedelta(0))\n",
            "<ipython-input-132-b17b2be7c65d>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  conn_features_df[feature] = conn_features_df[feature].dt.total_seconds().astype(int)\n",
            "<ipython-input-132-b17b2be7c65d>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  conn_features_df[feature] = conn_features_df[feature].fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 LABEL ENCODING ####"
      ],
      "metadata": {
        "id": "YVEUn4BH7ywF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevant Considerations\n",
        "# -- The ABOD (Angle-based Outlier Detection) algorithm is a distance-based outlier \n",
        "# -- detection algorithm that measures the angles between points in a high-dimensional space to detect outliers. \n",
        "\n",
        "# -- As a distance-based algorithm, it requires that all input features be numeric, as it relies on computing distances between points in the feature space.\n",
        "# -- If your data contains non-numeric features, such as string values in some columns, then the ABOD algorithm will not be able to compute distances correctly \n",
        "# -- and will not be able to fit the data. This is normal behavior for distance-based algorithms like ABOD.\n",
        "\n",
        "# -- To use the ABOD algorithm on your data, you will need to preprocess your data to convert the string features into numeric ones. \n",
        "# -- There are several ways to do this, depending on the specific characteristics of your data. One common approach is to use one-hot encoding or \n",
        "# -- label encoding to convert categorical features into numerical features that can be used by the algorithm.\n",
        "\n",
        "# -- Alternatively, you may consider using a different outlier detection algorithm that can handle mixed data types, \n",
        "# -- such as the Isolation Forest algorithm or the Local Outlier Factor algorithm. These algorithms can handle both numeric and categorical features, \n",
        "# -- and can be used on mixed data types without requiring feature preprocessing."
      ],
      "metadata": {
        "id": "suhglnyO8iiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing - LabelEncoding\n",
        "# -- Another option might be using OneHotEncoding\n",
        "le = LabelEncoder()\n",
        "for feature in features:\n",
        "    if (conn_features_df[feature].dtype.name == 'category') :\n",
        "        print(feature)\n",
        "        conn_features_df[feature] = le.fit_transform(conn_features_df[feature])\n",
        "\n",
        "# Dataframe conversion to float\n",
        "conn_features_df = conn_features_df.astype(float)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIdoCzMJ9i39",
        "outputId": "a916a416-c272-4def-c9d4-981ab74f3b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "service\n",
            "history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 NUMPY ARRAY CREATION ####"
      ],
      "metadata": {
        "id": "qUpN0n1H8HkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataframe to a numpy array\n",
        "X = conn_features_df.to_numpy()\n",
        "print(X[0:10,:])\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwXvEvTHC6ld",
        "outputId": "494e73d4-c8b0-4a4c-e675-036558db5836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.40000000e+01 0.00000000e+00 2.20000000e+02 1.79000000e+02\n",
            "  4.75000000e+02 8.00000000e+00 8.00000000e+00 1.37500000e+01\n",
            "  1.11875000e+01 5.32535210e+01 4.33290010e+01 4.40000000e-05\n",
            "  1.06000000e-04]\n",
            " [1.40000000e+01 0.00000000e+00 3.00000000e+02 1.47200000e+03\n",
            "  4.37000000e+02 1.00000000e+01 6.00000000e+00 1.66666670e+01\n",
            "  8.17777780e+01 6.87184270e+01 3.37178416e+02 5.40000000e-05\n",
            "  1.66000000e-04]\n",
            " [1.40000000e+01 0.00000000e+00 1.38800000e+03 1.41500000e+03\n",
            "  4.75000000e+02 8.00000000e+00 8.00000000e+00 8.67500000e+01\n",
            "  8.84375000e+01 3.35981305e+02 3.42516965e+02 7.60000000e-05\n",
            "  1.88000000e-04]\n",
            " [1.40000000e+01 0.00000000e+00 2.26000000e+02 1.85000000e+02\n",
            "  4.75000000e+02 8.00000000e+00 8.00000000e+00 1.41250000e+01\n",
            "  1.15625000e+01 5.47058900e+01 4.47813700e+01 3.50000000e-05\n",
            "  7.20000000e-05]\n",
            " [1.40000000e+01 0.00000000e+00 3.06000000e+02 1.47200000e+03\n",
            "  4.37000000e+02 1.00000000e+01 6.00000000e+00 1.70000000e+01\n",
            "  8.17777780e+01 7.00927960e+01 3.37178416e+02 4.70000000e-05\n",
            "  1.31000000e-04]\n",
            " [1.00000000e+00 0.00000000e+00 1.48000000e+02 2.70000000e+02\n",
            "  3.00000000e+00 2.00000000e+00 2.00000000e+00 2.96000000e+01\n",
            "  5.40000000e+01 5.92000000e+01 6.61362230e+01 5.50000000e-05\n",
            "  8.60000000e-05]\n",
            " [1.00000000e+00 0.00000000e+00 8.60000000e+01 2.08000000e+02\n",
            "  3.00000000e+00 2.00000000e+00 2.00000000e+00 1.72000000e+01\n",
            "  4.16000000e+01 3.44000000e+01 5.09493870e+01 4.00000000e-05\n",
            "  5.60000000e-05]\n",
            " [1.00000000e+00 0.00000000e+00 8.00000000e+01 2.76000000e+02\n",
            "  3.00000000e+00 2.00000000e+00 2.00000000e+00 1.60000000e+01\n",
            "  5.52000000e+01 3.20000000e+01 6.76059170e+01 2.44230000e-02\n",
            "  4.88420000e-02]\n",
            " [1.00000000e+00 0.00000000e+00 5.10000000e+01 1.49000000e+02\n",
            "  3.00000000e+00 1.00000000e+00 1.00000000e+00 1.70000000e+01\n",
            "  4.96666670e+01 2.40416310e+01 7.02392740e+01 4.05430000e-02\n",
            "  5.73360000e-02]\n",
            " [1.00000000e+00 0.00000000e+00 1.00000000e+02 3.30000000e+02\n",
            "  3.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+01\n",
            "  6.60000000e+01 4.00000000e+01 8.08331620e+01 1.26720000e-02\n",
            "  2.53410000e-02]]\n",
            "(303380, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. CLASSIFICATION ALGORITHMS ###"
      ],
      "metadata": {
        "id": "-ttZ7WvM8NOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random State 42\n",
        "# -- In NumPy, the random_state parameter is used to set the seed for the \n",
        "# -- random number generator, which determines the sequence of random numbers \n",
        "# -- generated by NumPy's random functions.\n",
        "\n",
        "# -- When you set random_state to a fixed value, you get a reproducible sequence \n",
        "# -- of random numbers every time you run your code. \n",
        "# -- This can be useful when you need to compare results across multiple runs \n",
        "# -- or when you want to ensure that the random numbers are the same each time you run your code.\n",
        "\n",
        "# -- In the case of random_state=42, the number 42 is an arbitrary value that \n",
        "# -- is commonly used as a default seed in many programming examples and tutorials.\n",
        "\n",
        "rs = np.random.RandomState(42)\n",
        "\n",
        "# Outlier detectetion algorithms\n",
        "clf = {\n",
        "    # 'Angle-based Outlier Detector (ABOD)': ABOD(contamination=0.1),\n",
        "    # 'Cluster-based Local Outlier Factor (CBLOF)': CBLOF(contamination=0.1, check_estimator=False, random_state=rs),\n",
        "    'Isolation Forest': IForest(contamination=0.1, random_state=rs),\n",
        "    # 'K Nearest Neighbors (KNN)': KNN(contamination=0.1),\n",
        "    # 'Average KNN': KNN(method='mean', contamination=0.1),\n",
        "    # 'Local Outlier Factor (LOF)': LOF(n_neighbors=35, contamination=0.1),\n",
        "    'Copula Based Outlier Detector (COPOD)': COPOD(contamination=0.1),\n",
        "    'Emipirical-Cumulative-Distribution-based Outlier Detector (ECOD)': ECOD(contamination=0.1),\n",
        "    # 'One-class SVM (OCSVM)': OCSVM(contamination=0.1),\n",
        "}"
      ],
      "metadata": {
        "id": "JVhs8LtMBz8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all detectors\n",
        "for i, classifier in enumerate(clf.keys()):\n",
        "    print('Model', i + 1, classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ADAUFj4B2HC",
        "outputId": "846c6965-69b5-4330-af7f-af3e91c80289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Isolation Forest\n",
            "Model 2 Copula Based Outlier Detector (COPOD)\n",
            "Model 3 Emipirical-Cumulative-Distribution-based Outlier Detector (ECOD)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. MODEL FITTING - TRAINING - PREDICTION ###"
      ],
      "metadata": {
        "id": "VFaGIftI8cQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusters_separation = [0]\n",
        "clf_names = list(clf.keys())\n",
        "outliers_pred = np.zeros((X.shape[0], len(clf_names)))\n",
        "\n",
        "# Fit the models with the generated data and compare model performances\n",
        "for i, offset in enumerate(clusters_separation):\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Fit the model\n",
        "    for i, (classifier_name, classifier) in enumerate(clf.items()):\n",
        "\n",
        "        print(i + 1, 'fitting', classifier_name)\n",
        "\n",
        "        # Fit the data and tag outliers\n",
        "        classifier.fit(X)\n",
        "\n",
        "        # Scores prediction\n",
        "        scores_pred = classifier.decision_function(X) * -1\n",
        "        \n",
        "        # Outliers detection (based on prediction)\n",
        "        y_pred = classifier.predict(X)\n",
        "        outliers_pred[:,i] = y_pred;\n",
        "        \n",
        "        # Threshold explanation\n",
        "        # -- The command threshold = percentile(scores_pred, 100 * 0.1) is used \n",
        "        # -- to set a threshold for outlier detection based on the scores predicted by the algorithm.\n",
        "\n",
        "        # -- Scores_pred is a one-dimensional NumPy array of scores predicted by the outlier detection algorithm. \n",
        "        # -- The scores represent how \"outlying\" each data point is, with higher scores indicating a higher likelihood of being an outlier.\n",
        "\n",
        "        # -- Percentile(scores_pred, 100 * 0.1) computes the 10th percentile of the scores_pred array, which is the score \n",
        "        # -- value below which 10% of the data points fall. In other words, if a data point has a score below this threshold, it is considered an outlier.\n",
        "\n",
        "        # --  The resulting threshold value is assigned to the threshold variable for later use.The specific value of 0.1 in the command percentile(scores_pred, 100 * 0.1) is \n",
        "        # -- arbitrary and can be adjusted depending on the specific problem and the desired level of sensitivity to outliers. \n",
        "\n",
        "        # threshold = percentile(scores_pred, 100 * 0.05)\n",
        "        # num_outliers = (y_pred > threshold).sum()"
      ],
      "metadata": {
        "id": "fckjDi2oB_ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5cbada-b189-4eb5-d888-7794bf850e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 fitting Isolation Forest\n",
            "2 fitting Copula Based Outlier Detector (COPOD)\n",
            "3 fitting Emipirical-Cumulative-Distribution-based Outlier Detector (ECOD)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. RESULT ANALYSIS ###"
      ],
      "metadata": {
        "id": "kPQbkWBemkra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 OUTLIERS DATAFRAMES ###"
      ],
      "metadata": {
        "id": "FlqE0YvjmoZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New Dataframes to store each Outlier\n",
        "ABOD_out_df = pd.DataFrame()\n",
        "CBLOF_out_df = pd.DataFrame()\n",
        "IFOREST_out_df = pd.DataFrame()\n",
        "KNN_out_df = pd.DataFrame()\n",
        "AKNN_out_df = pd.DataFrame()\n",
        "LOF_out_df = pd.DataFrame()\n",
        "ECOD_out_df = pd.DataFrame()\n",
        "COPOD_out_df = pd.DataFrame()\n",
        "\n",
        "# Dropping NaNs from conn_df\n",
        "conn_df = log_to_df.create_dataframe('mpli_conn_ts.log');\n",
        "conn_df = conn_df.dropna()\n",
        "\n",
        "# Outliers Stored for each algorithm\n",
        "for i in range(outliers_pred.shape[0]):\n",
        "    if outliers_pred[i,0] == 1:\n",
        "        IFOREST_out_df = IFOREST_out_df.append(conn_df.iloc[i])\n",
        "    if outliers_pred[i,1] == 1:\n",
        "        COPOD_out_df = COPOD_out_df.append(conn_df.iloc[i])\n",
        "    if outliers_pred[i,2] == 1:\n",
        "        ECOD_out_df = ECOD_out_df.append(conn_df.iloc[i])\n",
        "\n",
        "# Numeric Data Types Correction\n",
        "IFOREST_out_df['sourcePort'] = np.uint16(IFOREST_out_df['sourcePort'])\n",
        "IFOREST_out_df['destinationPort'] = np.uint16(IFOREST_out_df['destinationPort'])\n",
        "COPOD_out_df['sourcePort'] = np.uint16(COPOD_out_df['sourcePort'])\n",
        "COPOD_out_df['destinationPort'] = np.uint16(COPOD_out_df['destinationPort'])\n",
        "ECOD_out_df['sourcePort'] = np.uint16(ECOD_out_df['sourcePort'])\n",
        "ECOD_out_df['destinationPort'] = np.uint16(ECOD_out_df['destinationPort'])\n",
        "\n",
        "\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        ABOD_out_df = ABOD_out_df.append(conn_df.iloc[i])\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        CBLOF_out_df = CBLOF_out_df.append(conn_df.iloc[i])\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        IFOREST_out_df = IFOREST_out_df.append(conn_df.iloc[i])\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        KNN_out_df = KNN_out_df.append(conn_df.iloc[i])\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        AKNN_out_df = AKNN_out_df.append(conn_df.iloc[i])\n",
        "#    if outliers_pred[i, x] == 1:\n",
        "#        LOF_out_df = LOF_out_df.append(conn_df.iloc[i])"
      ],
      "metadata": {
        "id": "H1Th39fmSmEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 ANOMALOUS IPs EXTRACTION ###"
      ],
      "metadata": {
        "id": "QTXIk56imxhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We extract unique malign FlowID Values\n",
        "IFOREST_out_df['flux_id'] = IFOREST_out_df['sourceAddress'].astype(str) + IFOREST_out_df['destinationAddress'].astype(str) + IFOREST_out_df['sourcePort'].astype(str) + IFOREST_out_df['destinationPort'].astype(str)\n",
        "IFOREST_flow_id_values = IFOREST_out_df['flux_id'].unique()\n",
        "\n",
        "COPOD_out_df['flux_id'] = COPOD_out_df['sourceAddress'].astype(str) + COPOD_out_df['destinationAddress'].astype(str) + COPOD_out_df['sourcePort'].astype(str) + COPOD_out_df['destinationPort'].astype(str)\n",
        "COPOD_flow_id_values = COPOD_out_df['flux_id'].unique()\n",
        "\n",
        "ECOD_out_df['flux_id'] = ECOD_out_df['sourceAddress'].astype(str) + ECOD_out_df['destinationAddress'].astype(str) + ECOD_out_df['sourcePort'].astype(str) + ECOD_out_df['destinationPort'].astype(str)\n",
        "ECOD_flow_id_values = ECOD_out_df['flux_id'].unique()\n"
      ],
      "metadata": {
        "id": "J-pW1_GklzCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. RESULT ANALYSIS ###"
      ],
      "metadata": {
        "id": "8h-435XWyWIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.A FROM ORIGINAL CSV ####"
      ],
      "metadata": {
        "id": "C2IFlKExyY2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Source with Labeled Data\n",
        "\n",
        "original_df = pd.read_csv('Tuesday-WorkingHours.pcap_ISCX.csv')\n",
        "print(original_df.columns)\n",
        "\n",
        "# Drop all rows in which column 'feature' does not fit a criteria\n",
        "malign_original_df = original_df.drop(original_df[original_df[' Label'] == 'BENIGN'].index)\n",
        "\n",
        "# Connection = SrcIP + DstIP\n",
        "if (' Source IP' and ' Destination IP' and ' Source Port' and ' Destination Port') in original_df.columns:\n",
        "    malign_original_df = malign_original_df.rename(columns={' Source IP': 'sourceAddress'})\n",
        "    malign_original_df = malign_original_df.rename(columns={' Destination IP': 'destinationAddress'})\n",
        "    malign_original_df = malign_original_df.rename(columns={' Source Port': 'sourcePort'})\n",
        "    malign_original_df = malign_original_df.rename(columns={' Destination Port': 'destinationPort'})\n",
        "\n",
        "# Unique malign labeled Flows\n",
        "malign_original_df['flux_id'] = malign_original_df['sourceAddress'].astype(str) + malign_original_df['destinationAddress'].astype(str) + malign_original_df['sourcePort'].astype(str) + malign_original_df['destinationPort'].astype(str)\n",
        "malign_flux_id_values = malign_original_df['flux_id'].unique()\n"
      ],
      "metadata": {
        "id": "kZVadtDzykWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive Detection\n",
        "detected_positives = 0\n",
        "\n",
        "for i in range (0, len(clf_names)):\n",
        "    if i == 0:\n",
        "        for flow_id in IFOREST_flow_id_values:\n",
        "            # Check if the concatenated value is in the list of ip_src_dest values\n",
        "            if flow_id in malign_flux_id_values:\n",
        "                detected_positives+=1\n",
        "        print('- IFOREST Results -')\n",
        "        print('Detected Positives:', detected_positives)\n",
        "        print('False Positives: ', len(IFOREST_flow_id_values) - detected_positives)\n",
        "        print('Undetected Malign:', len(malign_flux_id_values) - detected_positives)\n",
        "    if i == 1:\n",
        "        for flow_id in COPOD_flow_id_values:\n",
        "            # Check if the concatenated value is in the list of ip_src_dest values\n",
        "            if flow_id in malign_flux_id_values:\n",
        "                detected_positives+=1\n",
        "        print('- COPOD Results -')\n",
        "        print('Detected Positives:', detected_positives)\n",
        "        print('False Positives: ', len(COPOD_flow_id_values) - detected_positives)\n",
        "        print('Undetected Malign:', len(malign_flux_id_values) - detected_positives)\n",
        "    if i == 2:\n",
        "        for flow_id in ECOD_flow_id_values:\n",
        "            # Check if the concatenated value is in the list of ip_src_dest values\n",
        "            if flow_id in malign_flux_id_values:\n",
        "                detected_positives+=1\n",
        "        print('- ECOD Results -')\n",
        "        print('Detected Positives:', detected_positives)\n",
        "        print('False Positives: ', len(ECOD_flow_id_values) - detected_positives)\n",
        "        print('Undetected Malign:', len(malign_flux_id_values) - detected_positives)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGdpbQaYyoq8",
        "outputId": "500f76eb-8d28-4f79-f9b6-95bf1047b30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- IFOREST Results -\n",
            "Detected Positives: 4055\n",
            "False Positives:  26230\n",
            "Undetected Malign: 2915\n",
            "- COPOD Results -\n",
            "Detected Positives: 4100\n",
            "False Positives:  26129\n",
            "Undetected Malign: 2870\n",
            "- ECOD Results -\n",
            "Detected Positives: 8101\n",
            "False Positives:  21110\n",
            "Undetected Malign: -1131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.B FROM SCRIPT LABELED .LOG FILE ####"
      ],
      "metadata": {
        "id": "FLNEKq1myc6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe etiquetado según el Script creado\n",
        "labeled_conn_df = log_to_df.create_dataframe('mpli_conn_label.log');\n",
        "malign_conn_df = labeled_conn_df[labeled_conn_df['label'] == 'MALIGN'];\n",
        "malign_conn_df['flux_id'] = malign_conn_df['sourceAddress'].astype(str) + malign_conn_df['destinationAddress'].astype(str) + malign_conn_df['sourcePort'].astype(str) + malign_conn_df['destinationPort'].astype(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-oWbgQI0WkS",
        "outputId": "d7f563af-0cad-419a-b89d-19148c3f39f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-168-74832633f230>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  malign_conn_df['flux_id'] = malign_conn_df['sourceAddress'].astype(str) + malign_conn_df['destinationAddress'].astype(str) + malign_conn_df['sourcePort'].astype(str) + malign_conn_df['destinationPort'].astype(str)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectamos Detecciones Exitosas -> INNER JOIN\n",
        "\n",
        "# IFOREST RESULTS\n",
        "IFOREST_malign_common_df_1 = pd.merge(IFOREST_out_df, malign_conn_df, on='flux_id')\n",
        "\n",
        "print('- IFOREST Results - ')\n",
        "positives1 = len(IFOREST_malign_common_df_1)\n",
        "print('Detected positives: ' +str(positives1))\n",
        "print('Total Malign: ' + str(malign_conn_df.shape[0]))\n",
        "print('Undetected malign: ' +str(malign_conn_df.shape[0] - positives1))\n",
        "print('')\n",
        "\n",
        "# COPOD RESULTS\n",
        "COPOD_malign_common_df_1 = pd.merge(COPOD_out_df, malign_conn_df, on='flux_id')\n",
        "\n",
        "print('- COPOD Results - ')\n",
        "positives1 = len(COPOD_malign_common_df_1)\n",
        "print(positives1)\n",
        "\n",
        "# ECOD RESULTS\n",
        "ECOD_malign_common_df_1 = pd.merge(ECOD_out_df, malign_conn_df, on='flux_id')\n",
        "\n",
        "print('- ECOD Results - ')\n",
        "positives1 = len(ECOD_malign_common_df_1)\n",
        "print(positives1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enApZW8_1DIk",
        "outputId": "8f282a4c-b292-415d-ea4f-cd023858827c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- IFOREST Results - \n",
            "Detected positives: 3975\n",
            "Total Malign: 6401\n",
            "Undetected malign: 2426\n",
            "- COPOD Results - \n",
            "24\n",
            "- ECOD Results - \n",
            "3937\n"
          ]
        }
      ]
    }
  ]
}